\chapter{Background}
In this chapter, we describe preliminary knowledge and notaions used for the remaining parts of this thesis to make it easy for readers to follow.
\section{Machine Learning}
Recently, \textit{machine learning} has become a must-know term not only in academia but also in daily life due to the popularity of it's application in various fields. Machine learning can be considered as a branch of Artificial Intelligence which aims at providing systems the ability to automatically adapt to their environment and learn from experience without being explicitly programmed. According to \cite{mitchell1997machine}, machine learning is formally defined as:

\begin{definition}{}
\textit{A computer program is said to learn from experience $E$ with respect to some task $T$ and some performance measure $P$ if its performance on $T$, as measured by $P$, improves with experience $E$.}
\end{definition}

We denote $\mathcal{X}$ as domain dataset which encodes the complete information of a domain. For each domain, however, we are only able to collect a small fraction of domain dataset, $\mathcal{D}$, resulted from any observation, measurement or recording apparatus such that $\mathcal{D} \cup \mathcal{X}$. The set $\mathcal{D}$ is normally referred as training dataset. Machine Leanring techniques desire to exploit $\mathcal{D}$ to get useful information for constructing a model that generalizes nature of data source. The model is then used to make prediction or inference in unseen dataset, $\mathcal{U} = \mathcal{X} - \mathcal{D}$.

Machine Learning algorithms can be classified into three groups: supervised learning, unsupervised learning and reinforcement learning. Supervised learning proceed with datasets whose objects are associated to labels, while unsupervised learning works with datasets consisting of input data without labeled responses. Reinforcement Learning aims at designing machines and software agents that can automatically determine the ideal behaviour within a specific context, in order to maximize its performance. Simple reward feedback is required for the agent to learn its behaviour; this is known as the reinforcement signal. In this thesis, we focus on supervised learning scenario. 

We consier a training set $\mathcal{D}$ generated by an unknown probability distribution $\mathcal{P}$,  $\mathcal{D} = \lbrace (x_1, y_1), (x_2, y_2),\ldots, (x_n, y_n)  \rbrace$ where $x_i \in \mathcal{X}$ are examples and $y_i \in \mathcal{Y}$ are labels. The relations between $x_i$ and $y_i$ are defined by a true function (target function) $f: \mathcal{X}\longmapsto \mathcal{Y}$. What we desire to do is to learn the function $f$. However, the only information we can access is from the training set. Therefore, a supervised learning method aims at estimating a function $g$ based on $\mathcal{D}$ to be as close to $f$ as possible. Depending on the domain of $\mathcal{Y}$, we can further group supervised learning methods into following sub-groups:
\begin{itemize}
	\item if $\mathcal{Y} = \mathcal{R}$, the problem is called regression
	\item if $|\mathcal{Y}| = 2$, we have a binary classification problem.
	\item if $|\mathcal{Y}| = n$, we have multi-class classification problem.
\end{itemize}

There is normally more than one possible choice for $g$. We refer each choice of $g$ as a hypothesis ($h$) or model and the set of all possible $g$ as hypothesis space, $\mathcal{H}$. A hypothesis space need to be define in advance and it is necessary to contains good approximations to target function. In order to find the optimal hypothesis, $h^*$, one way is to employ a true loss function, $\mathcal{L}$, which measures how much a hypothesis fails to correctly map between examples and their corresponding labels.
\begin{equation}
\label{loss-function}
R(h) = \int_{\mathcal{X}\times \mathcal{Y}}^{} \mathcal{L}(h(x),y)dP(x,y)
\end{equation}
The optimal function with the least of mis-mappings (errors) is then the solution of following optimization:
\begin{equation}
\label{opt-loss-function}
h^{*} = \arg\min_{h \in \mathcal{H}}R(h)
\end{equation}
Unfortunately, it is impossible to directly the optimization \ref{loss-function} since the probability distribution $\mathcal{P}$ in true loss function \ref{opt-loss-function} is an unknown function and we only have access to a finite training set $\mathcal{D}$. In this case, an alternative approach is to use empirical loss instead of true loss function. The empirical loss function is defined over the training set as follow:
\begin{equation}
R_{emp}(h) = \frac{1}{n} \sum_{n=1}^{n} |h(x_i) - y_i| 
\end{equation}
However, in order to use $R_{emp}(h)$, we need to guarantee that the value of $R_{emp}(h)$ converges to the value of $R(h)$?. Using the law of large numbers, authors prove in \cite{vapnik1998statistical} that the convergence happens when the number of examples is high enough. For more details we refer the reader an amazing book \cite{vapnik1998statistical}.
\section{Kernel Methods}
\label{kernel-methods}
In classical machine learning techniques for binary classification, first the data presentation form is defined, strings, vectors for instances. It then is used to represent for each example, $x \in X \longrightarrow \phi(x) \in \mathcal{F}$. After a linear function is learnt to separate positive examples from negative ones. Although these approaches have sucessfully applied in some cases, they share two common limitations: \textit{i}) the high comlexity when working with high dimensional spaces. \textit{ii}) the difficulty or impossiblity to find the vectorical form to represent data in many cases.

Recently, a new framework named Kernel method has been proposed and shown the state-of-the-art results in many cases of various fields. SVM \cite{cortes1995support} is a typical example of kernel methods. Unlike the presentation of data in traditional machine learning, data are not individually represented in kernel methods, but through a set of pairwise similarities. More precisely, a matrix whose each element is a real-valued comparision between two examples is used to represent for a data set. These real-valued elements are computed by using a kernel function: $k: \mathcal{X} \times \mathcal{X} \longmapsto R$. By using matrix to represent for data set, the presentation of data in kernel methods does not depend on the nature of objects. That means the presentation of strings, images,\ldots are the same. More interesting, it allows kernel machines to modularize into two components: the design of a specific kernel function and the design of a general learning algorithm.
\section{Kernel functions}
As stated in \ref{kernel-methods}, in kernel methods, the definition of kernel functions is independent from the definition general learning algorithms. Therefore, different kernel functions have been proposed for different types of data. In this section, we formally define what is a kernel function.
\subsection{Perceptron Method}
\subsection{Support Vector Machine}
\section{Graph Node Kernels}
Let us consider an undirected, weighted graph $G = (V, E)$ representing genes and relationships among them. The adjacency matrix $\textbf{A}$ is a symmetric matrix used to characterize the direct links between vertices $v_{i}$ and $v_{j}$ in the graph. Any entry $A_{ij}$ is equal to $w_{ij}$ when there exists an edge of weight $w_{ij}>0$ connecting $v_{i}$ and $v_{j}$, and is 0 otherwise. The Laplacian matrix $\textbf{L}$ is defined as $\textbf{L} = \textbf{D}-\textbf{A}$, where $\textbf{D}$ is the diagonal matrix with non-null entries equal to the summation over the corresponding row of the adjacency matrix, i.e. $D_{ii}=\sum_j A_{ij}$. The following graph node kernels are described under this notation convention.
\subsubsection*{Laplacian exponential diffusion kernel}
One of the most well-known kernels for graphs is the Laplacian exponential diffusion kernel $\textbf{K}_{LED}$, as it is widely used for exploiting discrete structures in general and graphs in particular. On the basis of the heat diffusion dynamics, Kondor and Lafferty proposed $\textbf{K}_{LED}$ in \cite{ledk}: imagine to initialize each vertex with a given amount of heat and let it flow through the edges until an arbitrary instant of time. The similarity between any vertex couple $v_{i}$, $v_{j}$ is the amount of heat starting from $v_{i}$ and reaching $v_{j}$ within the given time. Therefore, $\textbf{K}_{LED}$ can capture the long range relationship between vertices of a graph to define the global similarities. Below is the formula to compute $\textbf{K}_{LED}$ values:
\begin{equation} \label{LEDK-formula}
\textbf{K}_{LED} = e^{-\beta \textbf{L}} = \textbf{I} - \beta \textbf{L} + \frac{\beta \textbf{L}^{2}}{2!} - ...
\end{equation}
where $\beta$ is the diffusion parameter and is used to control the rate of diffusion and $\textbf{I}$ is the identity matrix. Choosing a consistent value for $\beta$ is very important: on the one side, if $\beta$ is too small, the local information cannot be diffused effectively and, on the other side, if it is too large, the local information will be lost. $\textbf{K}_{LED}$ is positive semi-definite as proved in \cite{ledk}.
\subsubsection*{Exponential diffusion kernel}
In $\textbf{K}_{LED}$, similarity values between high degree vertices is generally higher compared to that between low degree ones. Intuitively, the more paths connect two vertices, the more heat can flow between them. This could be problematic since peripheral nodes have unbalanced similarities with respect to central nodes. In order to make the strength of individual vertices comparable, a modified version of $\textbf{K}_{LED}$ was introduced by Chen et al in \cite{mrf}, called Markov exponential diffusion kernel $\textbf{K}_{MED}$ and given by the following formula:
\begin{equation} \label{MEDK-formula}
\textbf{K}_{MED} = e^{-\beta \textbf{M}}
\end{equation}
The difference with respect to the Laplacian diffusion kernel is the replacement of $\textbf{L}$ by the matrix $\textbf{M}=(\textbf{D}-\textbf{A}-n\textbf{I})/n$ where $n$ is the total number of vertices in graph. The role of $\beta$ is the same as for $\textbf{K}_{LED}$.
\subsubsection*{Markov diffusion kernel}
The original Markov diffusion kernel $\textbf{K}_{MD}$ was introduced by Fouss et al. \cite{mdk} and exploits the idea of diffusion distance, which is a measure of how similar the pattern of heat diffusion is among a pair of initialized nodes. In other words, it expresses how much nodes "influence" each other in a similar fashion. If their diffusion ways are alike, the similarity will be high and, vice versa, it will be low if they diffuse differently. This kernel is computed starting from the transition matrix $\textbf{P}$ and by defining $\textbf{Z}(t) = \frac{1}{t}\sum_{\tau=1}^{t}\textbf{P}^{\tau}$, as follows:
\begin{equation} \label{MDK-formula}
\textbf{K}_{MD} = \textbf{Z}(t)\textbf{Z}^{\top}(t)
\end{equation}
\subsubsection*{Regularized Laplacian kernel}
Another popular graph node kernel function used in graph mining is the regularized Laplacian kernel $\textbf{K}_{RL}$. This kernel function was introduced by Chebotarev and Shamis in \cite{rlk} and represents a normalized version of the random walk with restart model. It is defined as follows:
\begin{equation} \label{RLK-formula}
\textbf{K}_{RL} = \sum_{n=0}^{\infty}\beta^{n}(-\textbf{L})^n = (\textbf{I} + \beta \textbf{L})^{-1}
\end{equation}
where the parameter $\beta$ is again the diffusion parameter. $\textbf{K}_{RL}$ counts the paths connecting two nodes on the graph induced by taking $-\textbf{L}$ as the adjacency matrix, regardless of the path length. Thus, a non-zero value is assigned to any couple of nodes as long as they are connected by any indirect path. $\textbf{K}_{RL}$ remains a relatedness measure even when diffusion factor is large, by virtue of the negative weights assigned to self-loops.

\section{Disease Gene Prioritization}
Let us formally define the problem of disease gene prioritization employed in our empirical experiments to evaluate of different adopted methods. We consider a list of genes $\mathcal{G} = \lbrace g_{1}, g_{2},...,g_{n}\rbrace$ that could either be the full list of human genes or a subset of it. Considering a specific disease, there exists a set $P_{i}\subseteq \mathcal{G}$ of genes known to be associated with it. Its complementary set $U_{i}=\mathcal{G} \setminus P_{i}$ contains genes that are not a priori related to the disease, but we assume that inside $U_i$ some positive genes are hidden. Therefore, our aim is to build an efficient disease gene prioritization/classification model that allows to prioritize/classify the genes in $U_{i}$ based on their likelihood to be related to $P_{i}$. In particular, G1 will take a set of data sources $\mathcal{S}=\lbrace S_{1}, S_{2},...,S_{m} \rbrace$ and a set of disease genes $P_{i}$ as the input. The output is a list of scores, each score representing the proximity of a gene in $U_{i}$ to the genes in $P_i$.