\chapter{Background}
\label{chap:background}
In this chapter, we describe preliminary knowledge and notaions used for the remaining parts of this thesis to make it easy for readers to follow.
\section{Machine Learning}
Recently, \textit{machine learning} has become a must-know term not only in academia but also in daily life due to the popularity of it's applications in various fields. Machine learning can be considered as a branch of Artificial Intelligence which aims at providing systems the ability to automatically adapt to their environment and learn from experience without being explicitly programmed. According to \cite{mitchell1997machine}, machine learning is formally defined as:

\begin{definition}{}
\textit{A computer program is said to learn from experience $E$ with respect to some task $T$ and some performance measure $P$ if its performance on $T$, as measured by $P$, improves with experience $E$.}
\end{definition}

We denote $\mathbb{X}$ as domain dataset which encodes the complete information of a domain. For each domain, however, we are only able to collect a small fraction of domain dataset, $\mathbb{D}$, resulted from any observation, measurement or recording apparatus such that $\mathbb{D} \cup \mathbb{X}$. The set $\mathbb{D}$ is normally referred as the training dataset. Machine Leanring techniques desire to exploit $\mathbb{D}$ to get useful information for constructing a model that generalizes nature of data source. The model is then used to make prediction or inference in unseen dataset, $\mathbb{U} = \mathbb{X} - \mathbb{D}$.

Machine Learning algorithms can be classified into three groups: supervised learning, unsupervised learning and reinforcement learning. Supervised learning proceed with datasets whose objects are associated to labels, while unsupervised learning works with datasets consisting of input data without labeled responses. Reinforcement Learning aims at designing machines and software agents that can automatically determine the ideal behaviour within a specific context, in order to maximize its performance. Simple reward feedback is required for the agent to learn its behaviour; this is known as the reinforcement signal. In this thesis, we focus on supervised learning scenario. 

We consider a training set $\mathbb{D}$ generated by an unknown probability distribution $\mathcal{P}$,  $\mathbb{D} = \lbrace (x_1, y_1), (x_2, y_2),\ldots, (x_n, y_n)  \rbrace$ where $x_i \in \mathbb{X}$ are examples and $y_i \in \mathbb{Y}$ are labels. The relations between $x_i$ and $y_i$ are defined by a true function (target function) $f: \mathbb{X}\longmapsto \mathbb{Y}$. What we desire to do is to learn the function $f$. However, the only information we can access is from the training set. Therefore, a supervised learning method aims at estimating a function $g$ based on $\mathbb{D}$ to be as close to $f$ as possible. Depending on the domain of $\mathbb{Y}$, we can further group supervised learning methods into following sub-groups:
\begin{itemize}
	\item if $\mathbb{Y} \subseteq \mathbb{R}$, the problem is called regression
	\item if $\left\vert{\mathbb{Y}}\right\vert = 2$, we have a binary classification problem
	\item if $\left\vert{\mathbb{Y}}\right\vert = n$ with $n>2$, we have multi-class classification problem
\end{itemize}
Besides, a supervised learning algorithm is called multi-labels classification if an example could have more than one label associated with that. It is worth highlighting that there is normally more than one possible choice for $g$. We refer each choice of $g$ as a hypothesis ($h$) or model and the set of all possible $g$ as hypothesis space, $\mathbb{H}$. A hypothesis space need to be define in advance and it is necessary to contains good approximations to target function. In order to find the optimal hypothesis, $h^*$, one way is to employ a true loss function, $\mathcal{L}$, which measures how much a hypothesis fails to correctly map between examples and their corresponding labels.
\begin{equation}
\label{loss-function}
\mathcal{R}(h) = \int_{\mathbb{X}\times \mathbb{Y}}^{} \mathcal{L}(h(x),y)dP(x,y)
\end{equation}
The optimal function with the least of mis-mappings (errors) is then the solution of following optimization:
\begin{equation}
\label{opt-loss-function}
h^{*} = \arg\min_{h \in \mathbb{H}}\mathcal{R}(h)
\end{equation}
Unfortunately, it is impossible to directly solve the optimization \ref{loss-function} since the probability distribution $\mathcal{P}$ in the true loss function \ref{opt-loss-function} is an unknown function and we only have access to a finite training set $\mathbb{D}$. In this case, an alternative approach is to use empirical loss instead of true loss function. The empirical loss function is defined over the training set as follow:
\begin{equation}
\mathcal{R}_{emp}(h) = \frac{1}{n} \sum_{n=1}^{n} |h(x_i) - y_i| 
\end{equation}
However, in order to use $\mathcal{R}_{emp}(h)$, we need to guarantee that the value of $\mathcal{R}_{emp}(h)$ converges to the value of $\mathcal{R}(h)$?. Using the law of large numbers, authors prove in \cite{vapnik1998statistical} that the convergence happens when the number of examples is high enough. For more details we refer the reader an amazing book \cite{vapnik1998statistical}.
\section{Kernel Methods}
\label{kernel-methods}
In classical machine learning techniques for binary classification, first the data presentation form is defined, strings, vectors for instances. It then is used to represent for each example, $x\in\mathbb{X} \longrightarrow \phi(x) \in \mathbb{F}$. After a linear function is learnt to separate positive examples from negative ones. Although these approaches have sucessfully applied in some cases, they share two common limitations: \textit{i}) the high comlexity when working with high dimensional spaces. \textit{ii}) the difficulty or impossiblity to find the vectorical form to represent data in many cases.

Recently, a new framework named Kernel method has been proposed and shown the state-of-the-art results in many cases of various fields. SVM \cite{cortes1995support} is a typical example of kernel methods. Unlike the presentation of data in traditional machine learning, data are not individually represented in kernel methods, but through a set of pairwise similarities. More precisely, a matrix whose each element is a real-valued comparision between two examples is used to represent for a data set. These real-valued elements are computed by using a kernel function: $k: \mathbb{X} \times \mathbb{X} \longmapsto \mathbb{R}$. By using matrix to represent for data set, the presentation of data in kernel methods does not depend on the nature of objects. That means the presentation of strings, images,\ldots are the same. More interesting, it allows kernel machines to modularize into two components: the design of a specific kernel function and the design of a general learning algorithm (kernel machine).
\section{Kernel functions}
As stated in \ref{kernel-methods}, in kernel methods, the definition of kernel functions is independent from the definition of general learning algorithms. Therefore, it provides kernel machines more options when employing kernels. A number of kernel functions have been proposed for different types of data. In this section, we first formally define what is a kernel function. We then introduce some kernels defined on graphs that later on are used in our experiments.
\begin{definition}{}
\textit{Given a set of object $\mathbb{X}$, a function $k: \mathbb{X} \times \mathbb{X}\longmapsto \mathbb{R}$ is called a kernel on $\mathbb{X} \times \mathbb{X}$ iff $k$ is
\begin{itemize}
	\item symmetric: it means $k(x_1,x_2) = k(x_2,x_1)$, where $x_1, x_2 \in \mathbb{X}$.
	\item positive semi-definite: that is
	$\sum_{i=1}^{N}\sum_{j=1}^{N}c_ic_jk(x_i,x_j) \geq 0$ for any $N>0$, $c_i, c_j \in \mathbb{R}$, and  $x_i, x_j \in \mathbb{X}$.
\end{itemize}
}
\end{definition}
A kernel is usually represented as a matrix $K$ which is called Kernel matrix (Gram matix) and $K$ needs to be symmetric, i.e. $K(x_1,x_2) = K(x_2,x_1)$, positive semi-definite, i.e. its eigen values are non-negative. In this thesis, kernels and kernel matrcies are identical. 

One of the most simple kernel called Linear kernel which is defined on vectors, $\mathbb{X} \subseteq \mathbb{R}^n$. $k_L(x_1, x_2) = x_{1}^\intercal x_2$, where $x_1, x_2 \in \mathbb{X}$. This kernel suggests a systematic way to define kernels. Given a general set of object $\mathbb{X}$, we first project each element in $\mathbb{X}$ into a vector space, $x \in \mathbb{X} \longrightarrow \phi(x) \in \mathbb{R}^n$. Next, we define a kernel as:
\begin{equation}
k(x_1, x_2) = \phi(x_1)^\intercal \phi(x_2)
\end{equation}
Interestingly, any kernels defined on $\mathbb{X}$, there exists a Hilbert space, $\mathbb{F}$ and a mapping $\phi: \mathbb{X}\longrightarrow \mathbb{F}$ such that $k(x_1, x_2)= \langle \phi(x_1),\phi(x_2) \rangle$, where $x_1, x_2 \in \mathbb{X}$.

There are two problems we might face with if we would like to explicitly embed objects into a vector space. \textit{i}) We need to deal the high computation if we embed objects into high demensional spaces. \textit{ii}) We do not have clear way to represent objects in vectorial forms. These limitations are effectively solved by using \textit{Kernel trick}. The kernel trick avoids the explicit mapping. Instead, it allows the operations (dot product) between vectors in the feature space to be done by computing only in the input space.

A kernel is considered as a similarity (proximity) measure since its value computed for two objects is proportional to their similarity.

Most kernels are defined on vectorial form of data in which Radial basis function kernel (RBF) \cite{vert2004primer} is the most used one. However, real world data often cannot be represented in the vectorial form without lossing important information. Therefore, a high number of kernels are proposed to deal with structured data, including trees, graphs, etc. 

In many domains, relational data can be naturally represented by graphs (networks) whose nodes are entities and links characterize relations between entities. One example is the gene network where each node represents for a gene and each link is formed between two genes if they encode common protein(s). Another example is the social network whose nodes are users and links depict friendship between users. There are many systems have been proposed that take graphs as their input. These systems can be called as graph-based systems. One of the key points that determines the performance of graph-based systems is the definition of node similarity measure. Graph node kernels are popular and most used to measure the proximity between nodes of a graph. Following, we first give a formal definition of a graph as well as graph related definitions and notations. We then briefly describe kernels defined on graphs. Kernels on graphs could be designed on vertices of graphs or between graphs. We refer kernels in the former case as graph kernels and the latter one as graph node kernels.
\begin{definition}{}
\textit{A graph, notated as $G = \left(  \mathbb{V}, \mathbb{E} \right)$, is a structure which consists of a set of nodes (vertices), $V = \lbrace v_1, v_2,\ldots, v_n\rbrace$, and a set of links (edges), $\mathbb{E} = \lbrace (v_i, v_j)\rbrace \subseteq (\mathbb{V}\times \mathbb{V})$.}
\end{definition}

\begin{definition}{}
\textit{An adjacency matrix $\textbf{A}$ is a symmetric matrix used to characterize the direct links between vertices $v_{i}$ and $v_{j}$ in the graph. Any entry $A_{ij}$ is equal to 1 when there exists a link connecting $v_{i}$ and $v_{j}$, and is 0 otherwise.}
\end{definition}

\begin{definition}{}
\textit{The Laplacian matrix $\textbf{L}$ is defined as $\textbf{L} = \textbf{D}-\textbf{A}$, where $\textbf{D}$ is the diagonal matrix with non-null entries equal to the summation over the corresponding row of the adjacency matrix, i.e. $\textbf{D}_{ii}=\sum_j \textbf{A}_{ij}$.}
\end{definition}
\subsection{Graph Kernels}

\subsection{Graph Node Kernels}
It is different from graph kernels which aims at measuring similarities between graphs, graph node kernels intend to measure proximities between nodes in graphs. In the following, we introduce some of the most used graph node kernels.
\subsubsection{Laplacian exponential diffusion kernel}
One of the most well-known kernels for graphs is the Laplacian exponential diffusion kernel \textbf{LEDK}, as it is widely used for exploiting discrete structures in general and graphs in particular. On the basis of the heat diffusion dynamics, Kondor and Lafferty proposed \textbf{LEDK} in \cite{kondor2002diffusion}: imagine to initialize each vertex with a given amount of heat and let it flow through the edges until an arbitrary instant of time. The similarity between any vertex couple $v_{i}$, $v_{j}$ is the amount of heat starting from $v_{i}$ and reaching $v_{j}$ within the given time. Therefore, \textbf{LEDK} can capture the long range relationship between vertices of a graph to define the global similarities. Below is the formula to compute \textbf{LEDK} values:
\begin{equation} 
\label{LEDK-formula}
K = e^{-\beta \textbf{L}} = \textbf{I} - \beta \textbf{L} + \frac{\beta \textbf{L}^{2}}{2!} - ...
\end{equation}
where $\beta$ is the diffusion parameter and is used to control the rate of diffusion and $\textbf{I}$ is the identity matrix. Choosing a consistent value for $\beta$ is very important: on the one side, if $\beta$ is too small, the local information cannot be diffused effectively and, on the other side, if it is too large, the local information will be lost. \textbf{LEDK} is positive semi-definite as proved in \cite{kondor2002diffusion}.
\subsubsection{Exponential diffusion kernel}
In \textbf{LEDK}, the similarity values between high degree vertices are generally higher compared to those between low degree ones. Intuitively, the more paths connect two vertices, the more heat can flow between them. This could be problematic since peripheral nodes have unbalanced similarities with respect to central nodes. In order to make the strength of individual vertices comparable, a modified version of \textbf{LEDK} is introduced by Chen et al in \cite{chen2014disease}, called Markov exponential diffusion kernel \textbf{MEDK} and given by the following formula:
\begin{equation} \label{MEDK-formula}
\textbf{K} = e^{-\beta \textbf{M}}
\end{equation}
The difference with respect to the Laplacian diffusion kernel is the replacement of \textbf{L} by the matrix $\textbf{M}=(\textbf{D}-\textbf{A}-n\textbf{I})/n$ where $n$ is the total number of vertices in graph. The role of $\beta$ is the same as for \textbf{LEDK}.
\subsubsection{Markov diffusion kernel}
The original Markov diffusion kernel \textbf{MDK} was introduced by Fouss et al. \cite{fouss2006experimental} and exploits the idea of diffusion distance, which is a measure of how similar the pattern of heat diffusion is among a pair of initialized nodes. In other words, it expresses how much nodes "influence" each other in a similar fashion. If their diffusion ways are alike, the similarity will be high and, vice versa, it will be low if they diffuse differently. This kernel is computed starting from the transition matrix \textbf{P} and by defining $\textbf{Z}(t) = \frac{1}{t}\sum_{\tau=1}^{t}\textbf{P}^{\tau}$, as follows:
\begin{equation} 
\label{MDK-formula}
\textbf{K} = \textbf{Z}(t)\textbf{Z}^{\top}(t)
\end{equation}

\subsubsection{Regularized Laplacian kernel}
Another popular graph node kernel function used in graph mining is the regularized Laplacian kernel \textbf{RLK}. This kernel function is introduced by Chebotarev and Shamis in \cite{chebotarev2006matrix} and represents a normalized version of the random walk with restart model. It is defined as follows:
\begin{equation} 
\label{RLK-formula}
\textbf{K} = \sum_{n=0}^{\infty}\beta^{n}(-\textbf{L})^n = (\textbf{I} + \beta \textbf{L})^{-1}
\end{equation}
where the parameter $\beta$ is again the diffusion parameter. \textbf{RLK} counts the paths connecting two nodes on the graph induced by taking \textbf{-L} as the adjacency matrix, regardless of the path length. Thus, a non-zero value is assigned to any couple of nodes as long as they are connected by any indirect path. \textbf{RLK} remains a relatedness measure even when diffusion factor is large, by virtue of the negative weights assigned to self-loops.

\section{Kernel machine}
Traditional machine learning techniques aim at finding linear relations in datasets which are presented in vectorical forms. However, there are many cases where expected linear relations does not exist in input dataset. A solution to overcome these situations is to first explicitly transform data into a higher dimensional space and then search for linear relations in that space. Unlike traditional machine methods, kernel methods with the use of kernel functions are able to operate in a high-dimensional space without ever computing the coordinates of the data in that space, but rather by simply computing the inner products between the images of all pairs of data in the feature space. This operation is often computationally cheaper than the explicit computation of the coordinates.

A number of kernel methods have been proposed. Examples of kernel methods include Perceptron, support vector machines (SVM), Gaussian processes, principal components analysis (PCA), etc. In the next sections, we will introduce in detail two famous algorithms: Perceptron and SVM. For the simplicity, we describe these algorithms in the context of binary classification.
 
\subsection{Perceptron kernel algorithm}
Perceptron is an old, online leanring algorithm which is based on error-driven learning. It desires to learn a hyper-plane, $wx+b$ or $wx$ for simplicity, to separate positive examples from the negative ones in the training set. It is then used to predict a label for each unseen example, $x$, through \textit{sign} function. If $wx \geq 0$, $\hat{y} = sign(x) = 1$, otherwise $\hat{y} = sign\left( x\right)  = -1$. 

Perceptron works by first initilizing values for weight vector, $w$. It then iteratively improves the performance by updating the weight vector whenever a misclassification is found in the training set. Consider $y_i$ and $\hat{y_i}$ are true label and predicted label for $x_i$, if $y_i \neq \hat{y_i}$, $w$ is updated as follow:
\begin{center}
$w \longleftarrow w + \alpha y_i x_i$,
\end{center}
where $\alpha \in (0,1]$ is the learning rate. Suppose that $n$ misclassified examples are observed, the weight vector $w$ can be presented as:
\begin{center}
$w = \sum_{i=1}^{n} \alpha y_i x_i$.
\end{center}  
The interation is done when there is no error found. This algorithm guarantees that a linear separation is found if it exists. When the linear separation does not exist, a possible solution is to embed input data into a higher dimensional space. By virtue of doing so, there is a higher chance to have linear separation. However, a problem of high computation is raised when the algorithm operates in a high dimensional space. As a consequence, Perceptron kernel method, an extension of original Perceptron, is proposed to deal with high dimensional space.

Suppose that $\phi(x)$ is the image of $x$ in feature space. We rewrite the formula to compute the weight vector in feature space as:\\
\begin{center}
$w = \sum_{i=1}^{n} \alpha y_i \phi(x_i)$.
\end{center}
The \textit{sign} function is presented as:
\begin{center}
$sign(w \phi(x)) = \sum_{i=1}^{n} \alpha y_i x_i x_j$
\end{center}

One limitation of both Perceptron and Perceptron kernel method is that they are not able to find the optimal linear separation. Normally, a certain linear separation is supposed to not show promissing predicting ability for unseen examples. In the next section, we describe SVM, a kernel method, which aims at finding an optimal hyperplane to separate between positive and negative examples.

\subsection{Support vector machine}
The original Support vector machine is a linear classifier and it was invented by Vladimir N. Vapnik \cite{vapnik1963pattern}. SVM became popular when Vladimir et al introduced in \cite{boser1992training} a way to create nonlinear classifiers by employing the notion of kernel trick. In particular, a SVM searches for an optimal hyperplane in feature space, $\mathbb{H}$, through operations in input space only.

Given a set of training examples $\lbrace (x_1, y_1), (x_2, y_2),\ldots, (x_N, y_N) \rbrace$ in which $x_i \in \mathbb{R}^n$ and $y_i \in \lbrace \pm 1 \rbrace$, we first assume that the examples in the training set are linear separable. SVM tries to learn a linear function
\begin{equation}
\label{decision_svm}
f(x) = w^\intercal x + b
\end{equation}
where $b\in \mathbb{R}$ is bias and $w$ is the norm vector. This function forms two half-spaces $h^+ = \lbrace x: w^\intercal x \geq 1\rbrace$ and $h^- = \lbrace x: w^\intercal x \leq -1\rbrace$. The distance between these two half-spaces is referred as \textit{margin} and equal to $\frac{2}{\parallel w \parallel}$. To have all examples are correctly classified, the following condition needs to be satisfied 
\begin{equation}
\label{condition_svm}
y_i(wx_i + 1) \geq 1
\end{equation}
The optimal hyperplane is the solution of the below quadratic optimization problem (primal form):

\begin{equation}
\begin{aligned}
& \underset{w,b}{\text{maximize}}
& & \frac{2}{\| w \|} \\
& \text{subject to}
& & y_i(wx_i + 1) \geq 1
\end{aligned}
\end{equation}
It is equivalent to 

\begin{equation}
\label{optimization_svm}
\begin{aligned}
& \underset{w,b}{\text{minimize}}
& & \frac{1}{2}\| w \|^2 \\
& \text{subject to}
& & y_i(wx_i + 1) \geq 1
\end{aligned}
\end{equation}
The resulting Lagrange multiplier equation we desire to optimize is
\begin{equation}
\label{lagrange_svm}
L(w,b,\alpha) = \frac{1}{2} \| w \|^2 - \sum_{i=1}^{N}\alpha_{i}\left[ 
y_i(wx_i + b) -1 \right],
\end{equation}
where $\alpha_i \geq 0$ are Lagrange multipliers. Solving Lagrangian optimization \ref{lagrange_svm}, we obtain values for $w$, $b$ and $\alpha$ which determin a unique hyperplane. The $x_is$ corresponding to $\alpha_is$ which differ from 0 are called support vectors.

The formula of hyperplane decision function \ref{decision_svm} can be rewritten as:
\begin{equation}
f(x) = sign(\sum_{i=1}^{N} y_i \alpha_i \langle x,x_i \rangle + b)
\end{equation}
In the case that the training set is not linearly separable, we can apply kernel trick to let SVM operates in Hilbert space through calculating in the input space only. We achieve the following decision function:
\begin{equation}
f(x) = sign(\sum_{i=1}^{N} y_i \alpha_i \langle \phi(x),\phi(x_i) \rangle + b)
\end{equation}
There are usually very few $\alpha_is$ which are equal to 0. Therefore, it requires a low computation to predict for unseen examples.

In practice, there are two problems that we need to take into account. First, in many cases, the separating hyperplane does not exist due to the high level of noise in data, that is, a large part of examples in one side are located in the other side. Second, the learning function is so complex that it not only fits the examples, but it also fits the noise. Therefore, the learning function is able to classify well for training examples, but it fails to generalize for unseen data. The latter problem is called overfitting. In order to solve such problems, a solution one may think is to allow examples to violate \ref{condition_svm}. 

A soft margin SVM is introduced in which it allows to make a trade off between the mistakes on the training set and the complexity of the hypothesis. The optimization \ref{optimization_svm} is modified by introducing slack variables:
\begin{equation}
\label{optimization_softsvm}
\begin{aligned}
& \underset{w,b,\xi}{\text{minimize}}
& & \frac{1}{2}\| w \|^2 + C\sum_{i=1}^N \xi_i \\
& \text{subject to}
& & y_i(wx_i + 1) \geq 1 - \xi_i
\end{aligned}
\end{equation}
where $\xi_i \geq 0$ and $C$ is a constant which determines the trade-off between margin maximazation and the training error minimization.

\section{Disease Gene Prioritization}
Disease-gene association recovery is a major goal in molecular biology and medical that has received much attention from many researchers. Despite that fact that a big progress has been made in the last decades, a number of genes known to be related to a genetic disease is normally limited. In order to find out the complement set of the known disease gene set, one way is to search for whole genome or specific regions that often contain a large number of suspected genes (candidate genes). This is obvious not a good idea as it is expensive not only in term of time consuming but also from financial aspect. For this reason, a considerable number of gene prioritization methods have been proposed. A gene prioritization method aims at ordering candidate genes from the most to the least probable to be associated to the disease. The top genes in the ranking are then sent to biologists and medical scientists for further studies to determine whether each gene is related to considered disease. 

Let us formally define the problem of disease gene prioritization which is later on employed in our empirical experiments to evaluate of different adopted methods. We consider a list of genes $\mathcal{G} = \lbrace g_{1}, g_{2},...,g_{n}\rbrace$ that could either be the full list of human genes or a subset of it. Considering a specific disease, there exists a set $P_{i}\subseteq \mathcal{G}$ of genes known to be associated with it. Its complementary set $U_{i}=\mathcal{G} - P_{i}$ contains genes that are not a priori related to the disease, but we assume that inside $U_i$ some positive genes are hidden. Gene priorization is a task that allows to rank the genes in $U_{i}$ based on their likelihood to be related to $P_{i}$. 

\section{Biological Datasets}
The development of computational biology makes a high number of biological datasets available. Many biological datasets can be naturally represented as networks which are later on used as the input of graph-based biological systems. In biological networks, vertices are biological entities (genes and proteins, etc) and links describe the relation between entities. The relations can be discovered by either physical experiments and results from inferring methods (systems). Following we describe the way to extract information from some biological datasets and transform them into unweighted, undirected networks, represented in the forms of adjacency matrix. These networks will be employed in our experiments for evaluating the performance of different algorithms.

\textbf{Human Protein Reference Database} (\textbf{HPRD}) a database of curated proteomic information pertaining to human proteins. It is derived from \cite{keshava2008human} with 9,465 vertices and 37,039 edges. We employ the HPRD version used in \cite{chatr2014biogrid} that forms a graph which contains 7311 vertices (represent for genes) and 30503 links. In the graph, two vertices are linked if proteins encoded by their corresponding genes interact.

\textbf{BioGPS} \cite{wu2009biogps}. It contains expression profiles for 79 human tissues, which are measured by using the Affymetrix U133A array. Gene co-expression, defined by pairwise Pearson correlation coefficients (PCC), is used to build an unweighted graph. A pair of genes are linked by an edge if the PCC value is larger than 0.5.

\textbf{Pathways}. Pathway datasets are obtained from the database of KEGG \cite{ogata1999kegg}, Reactome \cite{vastrik2007reactome}, PharmGKB \cite{whirl2012pharmacogenomics} and PID \cite{schaefer2008pid}, which contain 280, 1469, 99 and 2679 pathways, respectively. A pathway co-participation network is constructed by connecting genes that co-participate in any pathway.

\textbf{String} \cite{jensen2008string}. The String database gathers protein information covering seven levels of evidence: genomic proximity in procaryotes, fused genes, co-occurrence in organisms, co-expression, experimentally validated physical interactions, external databases and text mining. Overall, these aspects focus on functional relationships that can be seen as edges of a weighted graph, where the weight is given by the reliability of that relationship. To perform the unbiased evaluation we employed the version 8.2 of String from which we extracted functional links among 17078 human genes.

\textbf{Phenotype similarity:} we use the OMIM \cite{mckusick2007mendelian} dataset and the phenotype similarity notion introduced by Van Driel et al. \cite{van2006text} based on the relevance and the frequency of the Medical Subject Headings (MeSH) vocabulary terms in OMIM documents. We built the graph linking those genes whose associated phenotypes have a maximal phenotypic similarity greater than a fixed cut-off value. Following \cite{van2006text}, we set the similarity cut-off to $0.3$. The resulting graph has 3393 nodes and 144739 edges.

\textbf{Biogridphys:} this dataset encodes known physical interactions among proteins. The idea is that mutations can affect physical interactions by changing the shape of proteins and their effect can propagate through protein graphs. We introduce a link between two genes if their products interact. The resulting graph has 15389 nodes and 155333 edges.

\textbf{Omim}: OMIM is a public database of disease-gene association. Genes implicated in the same disease are more likely to be involved in other similar diseases as well. Therefore, Omim network is formed by connecting genes which are involved in common disease(s).

\section{Link prediction}
We are witnessing a constant increase of the rate at which data is being produced and made available in machine readable formats. Interestingly it is not only the quantity of data that is increasing, but also its complexity, i.e. not only are we measuring a number of attributes or features for each data point, but we are also capturing their mutual relationships, that is, we are considering non independent and identically distributed (non i.i.d.) data. This yields collections that are best represented as graphs or relational data bases and requires a more complex form of analysis. As cursory examples of application domains that are social networks, where nodes are people and edges encode a type of association such as friendship or co-authorship, bioinformatics, where nodes are proteins and metabolites and edges represent a type of chemical interaction such as catalysis or signaling, and e-commerce, where nodes are people and goods and edges encode a ``buy'' or ``like'' relationship.
A key characteristic of this type of data collections is the sparseness and dynamic nature, i.e. the fact that the number of recorded relations is significantly smaller than the number of all possible pairwise relations, and the fact that these relations evolve in time. A crucial computational task is then the ``link prediction problem'' which allows to suggest friends, or possible collaborators for scientists in social networks, or to discover unknown interactions between proteins to explain the mechanism of a disease in biological networks, or to suggest novel products to be bought to a customer in a e-commerce recommendation system. Many approaches to link prediction that exist in literature can be partitioned according to \textit{i}) whether additional or ``side'' information is available for nodes and edges or rather only the network topology is considered and \textit{ii}) whether the approach is unsupervised or supervised. 

Unsupervised methods are non-adaptive (i.e. they do not have parameters that are tuned on the specific problem instance), and can therefore be computationally efficient. In general they define a score for any node pair that is proportional to the existence likelihood of an edge between the two nodes. \textit{Adamic-Adar} \cite{adamic} computes the weighted sum over the common neighbors where the weight is inversely proportional to the (log of) each neighbor node degree. The \textit{preferential attachment} method computes a score simply as the product of the node degrees in an attempt to exploit the ``rich get richer'' property of certain network dynamics. \textit{Katz} \cite{katz} takes into account the number of common paths with different lengths between two nodes, assigning more weight to shorter paths. The \textit{Leicht-Holme-Newman} method \cite{lhni} computes the number of intermediate nodes. In \cite{matrix-factorization} the score is derived from the singular value decomposition of the adjacency matrix. 

Supervised link prediction methods convert the problem into a binary classification task where links present in the network (at a given time) are considered as positive instances and a subset of all the non links are considered as negative instances. Following \cite{matrix-factorization}, we can further group these methods into four classes: feature-based models, graph regularization models, latent class models and latent feature models. 
A Bayesian nonparametric approach is used in \cite{nonparametric} to compute a nonparametric latent feature model that does not need a user defined number of latent features but rather induces it as part of the training phase. 
In \cite{matrix-factorization} a matrix factorization approach is used to extract latent features that can take into consideration the output of an arbitrary unsupervised method. The authors show a significant increase in predictive performance when considering a ranking loss function suitable for  the imbalance problem, i.e. when the number of negative is much larger than the number of positive instances. 

In general supervised methods exhibit better accuracies compared to unsupervised methods although incurring in much higher computational and memory complexity costs.
Moreover, most approaches implicitly represent the link prediction problem and the inference used to tackle it as a disjunction over the edges, that is, information on edges is propagated in such a fashion so that for a node to have $k$ neighbors or $k+1$ does not make a drastic difference.
We claim that this hypothesis is likely putting a cap on the discriminative power of classifiers and therefore we propose a novel supervised method that employs a conjunctive representation. We call the method ``joint neighborhood subgraphs link prediction'' (JNSL). The key idea here is to transform the link prediction task into a binary classification on suitable small subgraphs which we then solve using an efficient graph kernel method.
