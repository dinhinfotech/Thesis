\chapter*{Abstract}
The last decades have been experiencing a rapid growth in volume and diversity of biological data, thanks to the development of high-throughput technologies related to web services and embeded systems. It is common that information related to a given biological phenomenon is encoded in multiple data sources. On the one hand, this provides a great opportunity for biologists and data scientists to have more unified views about phenomenon of interest. On the other hand, this presents challenges for scientists to find optimal ways in order to wisely extract knowledge from such huge amount of data which normally cannot be done without the help of automated learning systems. Therefore, there is a high need of developing smart learning systems, whose input as set of multiple sources, to support experts to form and assess hypotheses in biology and medicine. In these systems, the problem of combining multiple data sources or data integration needs to be efficiently solved to achieve high performances.\\

Biological data can naturally be represented as graphs. By taking graphs for data representation, we can take advantages from the access to a solid and principled mathematical framework for graphs, and the problem of data integration is converted into graph-based integration. In recent years, the machine learning community has witnessed the tremendous growth in the development of kernel-based learning algorithms. Kernel methods whose kernel functions allow to separate between the representation of the data and the general learning algorithm. Interestingly, kernel representation can be applied to any type of data, including trees, graphs, vectors, etc. For this reason, kernel methods are a reasonable and logical choice for graph-based inference systems. However, there is a number of challenges for graph-based systems using kernel methods need to be effectively solved, including: \textit{definition of node similarity measure}, \textit{graph sparsity}, \textit{scalability}, \textit{integration methods}. The contributions of this thesis aim at investigating to propose solutions that overcome the challenges faced when constructing graph-based data integration learning systems.\\

The first contribution of the thesis is the definition of a novel decompositional graph node kernel, named conjunctive disjunctive node kernel, to measure graph node similarities. We first employ a network decomposition procedure to transform the network into a set of linked connected components in which we distinguish between \textit{conjunctive} links whose endpoints are in the same connected components and \textit{disjunctive} links that connect nodes located in different connected components. We then propose a graph node kernel that explicitly models the configuration of each nodeâ€™s context.\\

The second contribution aims at dealing with the sparsity problem of graphs by introducing a link prediction method whose objective is to recover missing links of a graph. In this method we first represent each link connecting two nodes by a graph composed of their neighborhood subgraphs. We then cast the link prediction problem as a binary classification task over obtained graphs in which we employ an efficient decompositional graph kernel for graph similarity. Empirical evaluation proves the promissing of the method.\\

The third contribution targets to boost the performance of diffusion-based graph node kernels when the graph structure is affected by noise in the form of missing links, similarities are distorted proportionally to the sparsity of
the graph and to the fraction of missing links. As a consequence, we propose a method named link enrichment for diffusion-based graph node kernels with the idea of carrying out the computation of information diffusion on a graph that contains edges identified by link prediction approaches. We discover a surprisingly robust signal that indicates that diffusion-based node kernels consistently benefit from the coupling with similarity-based link prediction techniques on large scale datasets in biological domains.\\

The fourth contribution copes with the scalability problem of graph-based data integration learning systems by proposing scalable kernel-based gene prioritization method (Scuba). Scuba is optimized to deal with strongly unbalanced setting and is able to deal with both large amount of candidate genes and arbitrary number of data sources. It enhances the scalability and efficacy and outperforms existing methods for disease gene prioritization.\\

The last contribution is another approach for graph-based data integration, targeting to solve disease gene prioritization problem. In this approach, the common genes between graph layers, derived from biological sources, are connected by disjunctive links. Then a particular graph node kernel is adopted to exploit topological graph features from all layers for measuring gene similarities. The state of the art performance on different experimental settings confirms the strength of the method. 
